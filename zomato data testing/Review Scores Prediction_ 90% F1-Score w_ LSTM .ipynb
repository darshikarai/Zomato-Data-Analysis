{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Simple LSTM baseline for predicting review scores\n\nIn this kernel, we will go through:\n\n1. **Preprocessing** - Load the dataset, retrieve the reviews (aka documents) and scores, encode the target (scores) and split into a training and test set.\n2. **Training Model** - We will train a simple LSTM model that will predict the rating based solely on the review comments. We will be using a FastText embedding; the matrix building process is inspired from [this excellent kernel](https://www.kaggle.com/thousandvoices/simple-lstm), and the LSTM model was simplified for learning purposes.\n3. **Evaluation** - We will plot the loss and accuracy progression through epochs, and display the classification results as a table."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import json\nimport re\n\nimport numpy as np \nimport pandas as pd\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\nfrom keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing import text, sequence\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## Loading data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/zomato-bangalore-restaurants/zomato.csv')\n\nprint(df.shape)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Retrieve the text data"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_ratings = []\n\nfor ratings in tqdm(df['reviews_list']):\n    ratings = eval(ratings)\n    \n    for score, doc in ratings:\n        if score:\n            score = score.strip(\"Rated\").strip()\n            doc = doc.strip('RATED').strip()\n            \n            score = float(score)\n            all_ratings.append([score, doc])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings_df = pd.DataFrame(all_ratings, columns=['score', 'doc'])\n\nprint(ratings_df.shape)\nratings_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Remove ratings inside text\n\nSome of the reviews have ratings within it. We want to train a generic model to predict ratings with only text, so we want to hide this extra information so the model does not overfit on that.\n\n\"Unhide\" the output of the next cell to view sample of the ratings that contain the character `\"/\"`."},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"docs_with_ratings = []\nfor doc in ratings_df['doc'][:150]:\n    if '/' in doc:\n        print(doc)\n        docs_with_ratings.append(doc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(docs_with_ratings))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will use Regex to find and replace all the occurences of ratings. \n\nLet's take a look at all the parts of documents that matches the pattern `[0-9.]*[0-9]/[0-9]*[0-9]`, which correspond to any rating that has double digits (e.g. 10/10), single digits (5/5) or single digits with a fraction (e.g. 9.5/10 or 3.5/5)."},{"metadata":{"trusted":true},"cell_type":"code","source":"for docs in docs_with_ratings:\n    x = re.findall('[0-9.]*[0-9]/[0-9]*[0-9]', docs)\n    print(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will replace them with the word \"score\", since we do not want the model to overfit on ratings that are already given in the comments."},{"metadata":{"trusted":true},"cell_type":"code","source":"doc = docs_with_ratings[0]\nsubbed_doc = re.sub('[0-9.]*[0-9]/[0-9]*[0-9]', 'score', doc)\nprint(\"ORIGINAL:\")\nprint(doc)\nprint(\"\\nSUBBED:\")\nprint(subbed_doc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we do it for all texts."},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings_df['new_doc'] = ratings_df['doc'].progress_apply(\n    lambda doc: re.sub('[0-9.]*[0-9]/[0-9]*[0-9]', 'score', doc)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One Hot Encoding"},{"metadata":{},"cell_type":"markdown","source":"Let's look at the distribution of ratings"},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings_df['score'].astype('category').value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly this is categorical data, with some heavy class imbalance. This is something to address if you want to improve performance. We will go ahead and encode that into binary labels:"},{"metadata":{"trusted":true},"cell_type":"code","source":"dummies = pd.get_dummies(ratings_df['score'])\ndummies.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Test Split\n\nFinally, we split the data into train and test sets; the latter will be used to evaluate our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(\n    ratings_df['new_doc'], \n    dummies, \n    test_size=0.1, random_state=2019\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building an LSTM Model\n\nAt this point, we are ready to build our model. Similar to the original kernel, we will go through the following steps:\n1. Fit the Keras Tokenizer\n2. Build an embedding matrix\n3. Tokenize and pad our training data\n4. Train the model\n\nOnce we are done training the model, we evaluate how well it performs. This part is covered in the next section."},{"metadata":{},"cell_type":"markdown","source":"## Helper functions to create fasttext embedding"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_matrix(word_index, path):\n    def get_coefs(word, *arr):\n        return word, np.asarray(arr, dtype='float32')\n\n    def load_embeddings(path):\n        with open(path) as f:\n            embedding_index = {}\n            \n            for line in tqdm(f):\n                word, arr = get_coefs(*line.strip().split(' '))    \n                if word in word_index:\n                    embedding_index[word] = arr\n            \n        return embedding_index\n\n    embedding_index = load_embeddings(path)\n    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n    \n    for word, i in tqdm(word_index.items()):\n        try:\n            embedding_matrix[i] = embedding_index[word]\n        except KeyError:\n            pass\n    return embedding_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(embedding_matrix):\n    words = Input(shape=(None,))\n    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n    x = SpatialDropout1D(0.2)(x)\n    x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n\n    hidden = concatenate([\n        GlobalMaxPooling1D()(x),\n        GlobalAveragePooling1D()(x),\n    ])\n    hidden = Dense(512, activation='relu')(hidden)\n    result = Dense(9, activation='softmax')(hidden)\n    \n    model = Model(inputs=words, outputs=result)\n    model.compile(\n        loss='categorical_crossentropy', \n        optimizer='adam',\n        metrics=['accuracy']\n    )\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the tokenizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nCHARS_TO_REMOVE = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—'\ntokenizer = text.Tokenizer(filters=CHARS_TO_REMOVE)\ntokenizer.fit_on_texts(list(x_train) + list(x_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix = build_matrix(tokenizer.word_index, '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = tokenizer.texts_to_sequences(x_train)\nx_test = tokenizer.texts_to_sequences(x_test)\nx_train = sequence.pad_sequences(x_train, maxlen=256)\nx_test = sequence.pad_sequences(x_test, maxlen=256)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model(embedding_matrix)\nmodel.summary()\n\ncheckpoint = ModelCheckpoint(\n    'model.h5', \n    monitor='val_acc', \n    verbose=1, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nhistory = model.fit(\n    x_train,\n    y_train,\n    batch_size=512,\n    callbacks=[checkpoint],\n    epochs=10,\n    validation_split=0.1\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluation"},{"metadata":{},"cell_type":"markdown","source":"## Training history\n\nLet's take a look at how well the model is training."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['acc', 'val_acc']].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Classification Report\n\nLet's see how well the model is able to predict each class of score, i.e. what is its F1-Score for each possible rating (1.0, 1.5, 2.0,...5.0)."},{"metadata":{},"cell_type":"markdown","source":"*Small note: Notice that we are using `keras.utils.to_categorical` here instead of `pd.get_dummies`. In theory both methods are the same, but the former is able to better encode integers (which is what we get when we perform an `np.array.argmax`), whereas the latter can better encode categorical data (i.e. `pd.Series` of `dtype='category'`). Feel free to experiment with both.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('model.h5')\n\ny_probs = model.predict(x_test, verbose=2)\ny_pred = to_categorical(y_probs.argmax(axis=1))\n\nreport = classification_report(y_test.values, y_pred, labels=y_test.columns)\nprint(report)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}